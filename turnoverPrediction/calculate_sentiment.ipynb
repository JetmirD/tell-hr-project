{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olt/Data/MLTest/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-15 13:53:26.238221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 13:53:26.278640: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 13:53:26.291153: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 13:53:26.358415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-15 13:53:27.249793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # For progress bar\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('user_responses_final.csv', usecols=[\n",
    "    'employeeID',\n",
    "    'salary_response',\n",
    "    'manager_response',\n",
    "    'benefits_response',\n",
    "    'career_response',\n",
    "    'environment_response',\n",
    "    'communication_response',\n",
    "    'support_response',\n",
    "    'recognition_response',\n",
    "    'leadership_response',\n",
    "    'remote_response',\n",
    "    'worklife_balance'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olt/Data/MLTest/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalized_sentiment_score(text):\n",
    "    if not str(text).strip():\n",
    "        # Handle empty strings by assigning neutral sentiment\n",
    "        return 0.5  # Normalized score for neutral sentiment\n",
    "    \n",
    "    try:\n",
    "        # Tokenize the input text and move tensors to the device\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "        \n",
    "        # Get the model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        # Convert probabilities to numpy array\n",
    "        probs = probs.detach().cpu().numpy()[0]\n",
    "        \n",
    "        # Verify that probabilities sum to 1\n",
    "        prob_sum = probs.sum()\n",
    "        if not 0.99 <= prob_sum <= 1.01:\n",
    "            print(f\"Warning: Probabilities do not sum to 1. Sum = {prob_sum}\")\n",
    "            probs = probs / prob_sum  # Normalize to sum to 1\n",
    "        \n",
    "        # Map probabilities to labels using indices\n",
    "        Pnegative = probs[0]  # Corresponds to Negative\n",
    "        Pneutral = probs[1]   # Corresponds to Neutral\n",
    "        Ppositive = probs[2]  # Corresponds to Positive\n",
    "        \n",
    "        # Compute Sentiment Score\n",
    "        sentiment_score = (Pnegative * 1) + (Pneutral * 2) + (Ppositive * 3)\n",
    "        \n",
    "        # Compute Normalized Sentiment Score\n",
    "        normalized_sentiment_score = (sentiment_score - 1) / 2  # Should be between 0 and 1\n",
    "        \n",
    "        # Ensure the normalized score is within [0,1]\n",
    "        normalized_sentiment_score = max(0, min(1, normalized_sentiment_score))\n",
    "        \n",
    "        return normalized_sentiment_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\\nException: {e}\")\n",
    "        # Assign neutral score in case of error\n",
    "        return 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Responses: 100%|██████████| 4519/4519 [04:56<00:00, 15.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store normalized sentiment scores\n",
    "salary_sentiment_scores = []\n",
    "manager_sentiment_scores = []\n",
    "benefits_sentiment_scores = []\n",
    "career_sentiment_scores = []\n",
    "environment_sentiment_scores = []\n",
    "communication_sentiment_scores = []\n",
    "support_sentiment_scores = []\n",
    "recognition_sentiment_scores = []\n",
    "leadership_sentiment_scores = []\n",
    "remote_sentiment_scores = []\n",
    "worlife_balance_sentiment_scores = []\n",
    "\n",
    "\n",
    "# Iterate over each row with a progress bar\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Responses\"):\n",
    "    # Get each response\n",
    "    salary_response = row['salary_response']\n",
    "    manager_response = row['manager_response']\n",
    "    benefits_response = row['benefits_response']\n",
    "    career_response = row['career_response']\n",
    "    environment_response = row['environment_response']\n",
    "    communication_response = row['communication_response']\n",
    "    support_response = row['support_response']\n",
    "    recognition_response = row['recognition_response']\n",
    "    leadership_response = row['leadership_response']\n",
    "    remote_response = row['remote_response']\n",
    "    worklife_balance_response = row['worklife_balance']\n",
    "    \n",
    "    # Compute normalized sentiment scores for each response\n",
    "    salary_normalized = compute_normalized_sentiment_score(salary_response)\n",
    "    manager_normalized = compute_normalized_sentiment_score(manager_response)\n",
    "    benefits_normalized = compute_normalized_sentiment_score(benefits_response)\n",
    "    career_normalized = compute_normalized_sentiment_score(career_response)\n",
    "    environment_normalized = compute_normalized_sentiment_score(environment_response)\n",
    "    communication_normalized = compute_normalized_sentiment_score(communication_response)\n",
    "    support_normalized = compute_normalized_sentiment_score(support_response)\n",
    "    recognition_normalized = compute_normalized_sentiment_score(recognition_response)\n",
    "    leadership_normalized = compute_normalized_sentiment_score(leadership_response)\n",
    "    remote_normalized = compute_normalized_sentiment_score(remote_response)\n",
    "    worklife_balance_normalized = compute_normalized_sentiment_score(worklife_balance_response)\n",
    "\n",
    "    salary_sentiment_scores.append(salary_normalized)\n",
    "    manager_sentiment_scores.append(manager_normalized)\n",
    "    benefits_sentiment_scores.append(benefits_normalized)\n",
    "    career_sentiment_scores.append(career_normalized)\n",
    "    environment_sentiment_scores.append(environment_normalized)\n",
    "    communication_sentiment_scores.append(communication_normalized)\n",
    "    support_sentiment_scores.append(support_normalized)\n",
    "    recognition_sentiment_scores.append(recognition_normalized)\n",
    "    leadership_sentiment_scores.append(leadership_normalized)\n",
    "    remote_sentiment_scores.append(remote_normalized)\n",
    "    worlife_balance_sentiment_scores.append(worklife_balance_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employeeID</th>\n",
       "      <th>salary_sentiment</th>\n",
       "      <th>manager_sentiment</th>\n",
       "      <th>benefits_sentiment</th>\n",
       "      <th>career_sentiment</th>\n",
       "      <th>environment_sentiment</th>\n",
       "      <th>communication_sentiment</th>\n",
       "      <th>support_sentiment</th>\n",
       "      <th>recognition_sentiment</th>\n",
       "      <th>leadership_sentiment</th>\n",
       "      <th>remote_sentiment</th>\n",
       "      <th>worklife_balance_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.160105</td>\n",
       "      <td>0.421617</td>\n",
       "      <td>0.568891</td>\n",
       "      <td>0.919296</td>\n",
       "      <td>0.909902</td>\n",
       "      <td>0.989616</td>\n",
       "      <td>0.044831</td>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.978631</td>\n",
       "      <td>0.052549</td>\n",
       "      <td>0.208987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.942415</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.988191</td>\n",
       "      <td>0.990024</td>\n",
       "      <td>0.990513</td>\n",
       "      <td>0.722745</td>\n",
       "      <td>0.045797</td>\n",
       "      <td>0.058123</td>\n",
       "      <td>0.439491</td>\n",
       "      <td>0.122708</td>\n",
       "      <td>0.103144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.627510</td>\n",
       "      <td>0.341362</td>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.351859</td>\n",
       "      <td>0.904192</td>\n",
       "      <td>0.954664</td>\n",
       "      <td>0.987931</td>\n",
       "      <td>0.601846</td>\n",
       "      <td>0.586047</td>\n",
       "      <td>0.981991</td>\n",
       "      <td>0.121754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.269852</td>\n",
       "      <td>0.054303</td>\n",
       "      <td>0.062823</td>\n",
       "      <td>0.060268</td>\n",
       "      <td>0.077351</td>\n",
       "      <td>0.975878</td>\n",
       "      <td>0.983771</td>\n",
       "      <td>0.070521</td>\n",
       "      <td>0.981046</td>\n",
       "      <td>0.255360</td>\n",
       "      <td>0.106225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.060565</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.038455</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>0.043418</td>\n",
       "      <td>0.205502</td>\n",
       "      <td>0.901055</td>\n",
       "      <td>0.058469</td>\n",
       "      <td>0.191105</td>\n",
       "      <td>0.388637</td>\n",
       "      <td>0.220065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employeeID  salary_sentiment  manager_sentiment  benefits_sentiment  \\\n",
       "0           1          0.160105           0.421617            0.568891   \n",
       "1           2          0.942415           0.990034            0.988191   \n",
       "2           3          0.627510           0.341362            0.824770   \n",
       "3           4          0.269852           0.054303            0.062823   \n",
       "4           5          0.060565           0.035477            0.038455   \n",
       "\n",
       "   career_sentiment  environment_sentiment  communication_sentiment  \\\n",
       "0          0.919296               0.909902                 0.989616   \n",
       "1          0.990024               0.990513                 0.722745   \n",
       "2          0.351859               0.904192                 0.954664   \n",
       "3          0.060268               0.077351                 0.975878   \n",
       "4          0.087962               0.043418                 0.205502   \n",
       "\n",
       "   support_sentiment  recognition_sentiment  leadership_sentiment  \\\n",
       "0           0.044831               0.987737              0.978631   \n",
       "1           0.045797               0.058123              0.439491   \n",
       "2           0.987931               0.601846              0.586047   \n",
       "3           0.983771               0.070521              0.981046   \n",
       "4           0.901055               0.058469              0.191105   \n",
       "\n",
       "   remote_sentiment  worklife_balance_sentiment  \n",
       "0          0.052549                    0.208987  \n",
       "1          0.122708                    0.103144  \n",
       "2          0.981991                    0.121754  \n",
       "3          0.255360                    0.106225  \n",
       "4          0.388637                    0.220065  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame with the sentiment scores\n",
    "sentiments_df = pd.DataFrame({\n",
    "    'employeeID': df['employeeID'],\n",
    "    'salary_sentiment': salary_sentiment_scores,\n",
    "    'manager_sentiment': manager_sentiment_scores,\n",
    "    'benefits_sentiment': benefits_sentiment_scores,\n",
    "    'career_sentiment': career_sentiment_scores,\n",
    "    'environment_sentiment': environment_sentiment_scores,\n",
    "    'communication_sentiment': communication_sentiment_scores,\n",
    "    'support_sentiment': support_sentiment_scores,\n",
    "    'recognition_sentiment': recognition_sentiment_scores,\n",
    "    'leadership_sentiment': leadership_sentiment_scores,\n",
    "    'remote_sentiment': remote_sentiment_scores,\n",
    "    'worklife_balance_sentiment': worlife_balance_sentiment_scores\n",
    "})\n",
    "\n",
    "# Display the first few rows to verify\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df['avg_sentiment'] = sentiments_df[\n",
    "    [\n",
    "        'salary_sentiment', 'manager_sentiment', 'benefits_sentiment', 'career_sentiment', 'environment_sentiment',\n",
    "        'communication_sentiment', 'support_sentiment', 'recognition_sentiment', 'leadership_sentiment',\n",
    "        'remote_sentiment', 'worklife_balance_sentiment'\n",
    "    ]\n",
    "].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment scores have been saved to 'sentiments.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the sentiments DataFrame to a CSV file\n",
    "sentiments_df.to_csv('sentiments_changed.csv', index=False)\n",
    "\n",
    "print(\"Sentiment scores have been saved to 'sentiments.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in salary_sentiment are within the [0, 1] range.\n",
      "All values in salary_sentiment are within the [0, 1] range.\n",
      "All values in manager_sentiment are within the [0, 1] range.\n",
      "All values in manager_sentiment are within the [0, 1] range.\n",
      "All values in benefits_sentiment are within the [0, 1] range.\n",
      "All values in benefits_sentiment are within the [0, 1] range.\n",
      "All values in career_sentiment are within the [0, 1] range.\n",
      "All values in career_sentiment are within the [0, 1] range.\n",
      "All values in environment_sentiment are within the [0, 1] range.\n",
      "All values in environment_sentiment are within the [0, 1] range.\n",
      "All values in communication_sentiment are within the [0, 1] range.\n",
      "All values in communication_sentiment are within the [0, 1] range.\n",
      "All values in support_sentiment are within the [0, 1] range.\n",
      "All values in support_sentiment are within the [0, 1] range.\n",
      "All values in recognition_sentiment are within the [0, 1] range.\n",
      "All values in recognition_sentiment are within the [0, 1] range.\n",
      "All values in leadership_sentiment are within the [0, 1] range.\n",
      "All values in leadership_sentiment are within the [0, 1] range.\n",
      "All values in remote_sentiment are within the [0, 1] range.\n",
      "All values in remote_sentiment are within the [0, 1] range.\n",
      "All values in worklife_balance_sentiment are within the [0, 1] range.\n",
      "All values in worklife_balance_sentiment are within the [0, 1] range.\n",
      "All values in avg_sentiment are within the [0, 1] range.\n",
      "All values in avg_sentiment are within the [0, 1] range.\n"
     ]
    }
   ],
   "source": [
    "for col in [\n",
    "        'salary_sentiment', 'manager_sentiment', 'benefits_sentiment', 'career_sentiment', 'environment_sentiment',\n",
    "        'communication_sentiment', 'support_sentiment', 'recognition_sentiment', 'leadership_sentiment',\n",
    "        'remote_sentiment', 'worklife_balance_sentiment', 'avg_sentiment'\n",
    "    ]:\n",
    "    if (sentiments_df[col] < 0).any() or (sentiments_df[col] > 1).any():\n",
    "        print(f\"Warning: {col} has values outside the [0, 1] range.\")\n",
    "    else:\n",
    "        print(f\"All values in {col} are within the [0, 1] range.\")\n",
    "        print(f\"All values in {col} are within the [0, 1] range.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
